<!DOCTYPE html>
<html>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=0.6">
        <title>Notes on the AI Race-to-the-Bottom | Notebook | Musa Haydar </title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Source+Serif+Pro:wght@400&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Ubuntu+Mono&display=swap" rel="stylesheet"> 
        <link rel="stylesheet" href="../css/style.css">
        <link rel="icon" href="../images/Moon_Sprite_Big.png">
    </head>
    <body>
        <div class="notebook">
            <div class="body_header">
                <h1>Notes on the AI Race-to-the-Bottom</h1>
                <div class="subtitle">Musa Haydar | Nov 26, 2025</div>
                <hr/>
            </div>
            <div class="about_body">
                <div class="body_text">
                    <p>This post serves to document some of my observations and thoughts on so-called generative AI, its use, and the present state of consumer software.</p>
                    <h3>AI Absolutely Everywhere</h3>
                    <p>Generative AI is not just everywhere. It's everywhere, beyond reason. Some examples:</p>
                    <ul>
                    <li><p>My Google pixel phone came pre-loaded with three "AI-powered" apps (which could not be deleted from the device). The phone's virtual assistant uses Gemini by default. More absurd, the messages app has a chat-with-Gemini button right beside the "new message" button, in addition to Gemini buttons appearing in Gmail, Google Docs, and on and on.</li></p>
                    <li><p>A fresh install of Google Chrome will have three AI buttons on the home landing page: one on top right of the application's menu bar, one on the right side of the address bar to activate "AI Mode" and yet another button on the Google Search bar for the same feature in the middle of the page.</li></p>
                    <li><p>Meta has been among the worst offenders of putting AI anywhere they can. For instance, on WhatsApp they added a chat-with-Meta-AI button next to the compose button on the home screen, and every time you type "@" to ping someone in a group, Meta AI is suggested. And the search bar to search through your messages now also functions as a place to prompt Meta AI.</li></p>
                    <li><p>Likewise on Instagram: not only is the main Instagram search bar now also a "Ask Meta AI" bar, but even the Instagram direct message search bar now has that function. Why would someone looking for a particular direct message write an AI prompt in that search bar at all? And every now and then Instagram notifies you that someone you follow is using the Meta AI app.</li></p>
                    <li><p>The Windows operating system follows suit. Now, you get two different AI/Copilot buttons when you right click a file, you get AI in the search bar and the Start Menu, and so on. Microsoft announced plans to make the entire operating system "agentic," and <a href="https://www.windowscentral.com/microsoft/windows-11/microsoft-ai-ceo-pushes-back-against-critics-after-recent-windows-ai-backlash-the-fact-that-people-are-unimpressed-is-mindblowing-to-me">were met with backlash</a>. Yet they still push forward.</li></p>
                    </ul>
                    <p>So why is AI functionality being crammed into every imaginable crevice of every consumer application? Working in tech, I've observed that it's a result of how these companies operate. Each team is trying to impress management and executives who are, in turn, trying to impress shareholders, each trying to get ahead on the corporate ladder. The actual quality of the product has nothing to do with it.  We're witnessing a hype cycle far more destructive than those before it because it is being applied almost anywhere a tech team can fit it in. And despite the sheer environmental destructiveness of these projects, <a href="https://www.newyorker.com/magazine/2025/11/03/inside-the-data-centers-that-train-ai-and-drain-the-electrical-grid">the datacenters are being built, and we're paying the cost</a>.</p>
                    <h3>What About It?</h3>
                    <p>There's so much to say about the effects of people coming to rely on AI. I'm not going to go into depth about this here, but I want to highlight a blog post that was trending on Hackernews: <a href="https://fokus.cool/2025/11/25/i-dont-care-how-well-your-ai-works.html">"I don't care how well your AI works,"</a> which discusses this quite succinctly:</p>
                    <div class="blockquote"><p>Our minds are susceptible to outside cues. When we read news articles we tend to believe what seems plausible. When we review code we generally expect it to behave the way it looks, even when we don't have the context to assess that. The same is true for text: When we let a model transform notes into a blog post, a lot of context and nuance is added. We read it and believe the output to be what we thought. It's subtle.</p>
                    <p>[quoted in the post]: "on a deeper level, writing is more than just the process by which you obtain a piece of text, right? it's also about finding out what you wanted to say in the first place, and how you wanted to say it. this post existed in my head first as a thought, then it started to gel into words, and then i tried pulling those words out to arrange them in a way that (hopefully) gets my point across. there is nothing extra there, no filler. i alone can get the thought out and writing is how i do that."</p></div>
                    <p>I recently had a conversation with someone about his use of ChatGPT for his schoolwork, where he tried to argue that he was only using it to help him understand his geometry homework. but he was still doing the work. Sure, he was still doing the actual arithmetic, but it seemed to me that what he was missing was developing the skill of figuring out how these formulas work. By relying on these tools, we not only run the risk of their inaccuracies but we fail to develop skills which we may not realize we develop when we push ourselves to work through problems.</p>
                    <p>Whether or not this counts as cheating or simply using a tool is besides the point. Our education systems have been prioritizing the wrong means of evaluation for a long time now.</p>
                    <div class="blockquote"><p>AI is no more destroying education than revealing how we lost the plot. If our students are cheating to get a good letter grade, or focused entirely on outputs, then we haven't taught them the most fundamental things they need to know to thrive, adapt, make meaning, or think critically in this world.</p></div>
                    <p>This quote comes from <a href="https://rushkoff.substack.com/p/is-ai-the-next-dumbwaiter">Douglas Rushkoff's Substack post</a>, which is worth a read for his insight about how tech companies' "demand for unbridled growth is reactionary â€” a way of doubling down on the same old colonizing way of doing things."</p>
                    <h3>And What Can We Do?</h3>
                    <p>I recently encountered a video by Nathan Laundry <a href="https://www.youtube.com/watch?v=PUtG4Zmd_AY">advocating for home-labbing, Linux, and open-source software as a counter-action to the attention economy.</a> I think his ideas extends to AI as well. The ultimate cause of the <a href="https://en.wikipedia.org/wiki/Enshittification">enshittification</a> of essentially all major consumer software  is due to the centralization within corporations who are now racing to the bottom. Certainly the state of the technology does not justify the expanse of its reign: the results of LLMs are still often inaccurate or incorrect, and image generation models still produce images immediately recognizable for fuzzy details and eerie flaws. No, the shareholders and executives believe generative AI can dramatically cut labor costs and are thus making these unfathomably large investments.</p>
                    <p>As Windows becomes more and more frustrating to use (and increasingly broken, <a href="https://support.microsoft.com/en-us/topic/kb5072911-multiple-symptoms-occur-after-provisioning-a-pc-with-a-windows-11-version-24h2-update-d2d30684-4e2b-47f5-9899-a00a8e0acb09">as even they are reporting</a>), I'm inching closer to ditching it altogether. With closed-source applications, you simply have to consume whatever the company is serving you, whether you like it or not. On the other hand, an open-source operating system can do what you want. (Plus, Linux is becoming increasingly accessible for non-technical users. For example, Valve is making major strides towards the Year of the Linux Desktop by enabling gaming for SteamOS.)</p>
                    <p>The <a href="https://news.ycombinator.com/item?id=46055944">Hackernews discussion</a> for the article I linked above involved a discussion of "Hacker values," which I would take with salt but there's an idea here that resonated with me. As said by user mattgreenrocks:</p>
                    <div class="blockquote"><p>[...] What began as a rejection of externally imposed values devolved into a mouthpiece of the current powers and principalities.</p>
                    <p>This is evidenced by the new set of hacker values being almost purely performative when compared against the old set. The tension between money and what you make has been boiled away completely. We lean much more heavily on where someone has worked ("ex-Google") vs their tech chops, which (like management), have given up on trying to actually evaluate. We routinely devalue craftsmanship because it doesn't bow down to almighty Business Impact.</p></div>
                    <p>This discussion pertains to some ideas of "Hacker culture" that are not well-defined, but the point here about values is important. When I think of Hacker values, what comes to mind is people like Aaron Swartz, who lived and died for his commitment to the freedom of information and collaboration that internet technology makes possible. Not those who grind leetcode and bend their knees to shareholder value. To quote from Rushkoff's article again:</p>
                    <div class="blockquote"><p>The Dawn of the early Internet was destabilizing to established institutions and ways of doing business. By creating new possibilities for people to connect exchange value and invent new forms together, it challenged businesses and institutions that were depending on doing things in the same old extractive and colonizing ways.</p>
                    <p>[...] Once money came into the picture, these very possibilities became the enemy. Once people are making bets on a new tech, they tend to favor probability over possibility.</p></div>
                    <p>We need to remember our values even when choosing what technologies we use and what projects we support. It isn't simply that all AI use-cases are bad. But right now, even using AI in ways that seem innocuous can have unintended consequences: consequences on our minds and for those who seek to control them. Like quoted above, we must not abstract away our thinking, and one way to reclaim our thinking is simply to write. We can choose and support open-source alternatives to mainstream platforms. <a href="https://www.michigandaily.com/news/administration/ypsilanti-residents-protest-umich-data-center-construction/">And we can push back.</a></p>
                </div>              
                <br/>
                <div class="links">
                    <p><a href="../notebook.html">Return</a></p>
                </div>
                <br/>       
            </div>
            <br/>
			<br/>
            <br/>
        </div>
    </body>
</html>